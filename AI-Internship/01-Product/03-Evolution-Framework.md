# Product Evolution Framework

## Purpose

This document defines how the code intelligence platform evolves from basic extraction to validated AI integration. Based on Microsoft's "Crawl-Walk-Run" framework and Chip Huyen's AI Engineering principles.

---

## Core Principle: Prove Value at Every Level

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THE PROOF REQUIREMENT                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  PROBLEM                                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Vanilla AI Editor (Claude Code/Cursor) + ERPNext = Generic responses       â”‚
â”‚                                                                              â”‚
â”‚  SOLUTION                                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  AI Editor + Code Intelligence Context = Domain-aware responses             â”‚
â”‚                                                                              â”‚
â”‚  PROOF REQUIRED                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Measurable improvement in:                                                  â”‚
â”‚  â€¢ Relevance - Does response match actual domain?                           â”‚
â”‚  â€¢ Completeness - Are bounded contexts surfaced?                            â”‚
â”‚  â€¢ Accuracy - Does it understand ERPNext's business rules?                  â”‚
â”‚                                                                              â”‚
â”‚  Without proof, the tool is just another experiment.                        â”‚
â”‚  With proof, it's a product that delivers value.                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Evolution Phases

### Phase 0: Baseline (Before Building Anything)

**Duration**: Week 1 (first 2 days)

**Purpose**: Establish what "vanilla" AI performance looks like.

```yaml
baseline_experiment:
  setup:
    ai_tool: "Claude Code"
    codebase: "ERPNext"
    context_provided: "none"  # Just the AI's built-in knowledge

  test_set:
    - question: "What happens when a Sales Invoice is submitted?"
    - question: "How is discount calculated in ERPNext?"
    - question: "What validations run on Invoice creation?"
    # ... 47 more questions (total: 50)

  capture:
    - response_text: "Full AI response"
    - accuracy_score: "1-5 (expert rated)"
    - completeness_score: "1-5 (expert rated)"
    - files_mentioned: "List of files AI referenced"
    - concepts_mentioned: "Domain concepts identified"
```

**Deliverable**: `experiments/baseline-v1.json`

```json
{
  "version": "baseline-v1",
  "date": "2026-01-14",
  "tool": "Claude Code 1.0",
  "context": "none",
  "aggregate_metrics": {
    "avg_accuracy": 2.3,
    "avg_completeness": 2.1,
    "file_accuracy": 0.35,
    "domain_concept_recall": 0.28
  },
  "questions": [
    {
      "id": "q001",
      "question": "What happens when a Sales Invoice is submitted?",
      "response": "When a Sales Invoice is submitted in ERPNext...",
      "accuracy": 2,
      "completeness": 2,
      "files_mentioned": ["sales_invoice.py"],
      "files_should_mention": ["sales_invoice.py", "gl_entry.py", "stock_ledger_entry.py"],
      "concepts_mentioned": ["submit", "GL Entry"],
      "concepts_should_mention": ["on_submit", "GL Entry", "Stock Ledger", "Payment Schedule"]
    }
  ]
}
```

---

### Phase 1: CRAWL - Static Extraction

**Duration**: Weeks 1-3

**Goal**: Parse ERPNext, extract symbols, generate basic context.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CRAWL PHASE DELIVERABLES                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  EXTRACTION                                                                  â”‚
â”‚  â”œâ”€â”€ AST parsing with tree-sitter                                           â”‚
â”‚  â”œâ”€â”€ Function/class extraction                                              â”‚
â”‚  â”œâ”€â”€ Import/dependency mapping                                              â”‚
â”‚  â””â”€â”€ DocType schema extraction (ERPNext-specific)                           â”‚
â”‚                                                                              â”‚
â”‚  OUTPUT                                                                      â”‚
â”‚  â”œâ”€â”€ symbols.json - All functions, classes, methods                         â”‚
â”‚  â”œâ”€â”€ imports.json - Import graph                                            â”‚
â”‚  â””â”€â”€ doctypes.json - ERPNext DocType schemas                                â”‚
â”‚                                                                              â”‚
â”‚  VALIDATION                                                                  â”‚
â”‚  â”œâ”€â”€ Coverage: 90%+ symbols extracted                                       â”‚
â”‚  â”œâ”€â”€ Parse success: 99%+ files without errors                               â”‚
â”‚  â””â”€â”€ Manual audit: Spot-check 20 files for correctness                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Success Criteria**:

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Symbol coverage | 90%+ | `extracted_symbols / total_symbols` |
| Parse success rate | 99%+ | `files_parsed / total_files` |
| Index time | < 5 min | Time full ERPNext indexing |

**Experiment at End of Crawl**:
```yaml
experiment_crawl:
  context_provided: "Raw symbol list for relevant module"
  expected_improvement: "10-15% accuracy increase"
  measure_against: "baseline-v1"
```

---

### Phase 2: WALK - Semantic Understanding

**Duration**: Weeks 4-6

**Goal**: Add relationships, embeddings, semantic search.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WALK PHASE DELIVERABLES                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  RELATIONSHIPS                                                               â”‚
â”‚  â”œâ”€â”€ Call graphs (function A calls function B)                              â”‚
â”‚  â”œâ”€â”€ Class hierarchies (inheritance)                                        â”‚
â”‚  â”œâ”€â”€ DocType relationships (links, child tables)                            â”‚
â”‚  â””â”€â”€ Event flows (hooks, triggers)                                          â”‚
â”‚                                                                              â”‚
â”‚  SEMANTIC LAYER                                                              â”‚
â”‚  â”œâ”€â”€ Embeddings for all symbols (bge-large-en-v1.5)                        â”‚
â”‚  â”œâ”€â”€ Vector index (LanceDB)                                                 â”‚
â”‚  â”œâ”€â”€ Semantic search (query â†’ relevant symbols)                             â”‚
â”‚  â””â”€â”€ Hybrid retrieval (keyword + semantic)                                  â”‚
â”‚                                                                              â”‚
â”‚  DOMAIN EXTRACTION                                                           â”‚
â”‚  â”œâ”€â”€ Business rules identified                                              â”‚
â”‚  â”œâ”€â”€ Validation logic extracted                                             â”‚
â”‚  â”œâ”€â”€ Workflow states mapped                                                 â”‚
â”‚  â””â”€â”€ Bounded contexts proposed                                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Success Criteria**:

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Retrieval precision@10 | 70%+ | RAGAs `context_precision` |
| Retrieval recall | 75%+ | RAGAs `context_recall` |
| Query latency (p95) | < 500ms | Langfuse tracing |

**Experiment at End of Walk**:
```yaml
experiment_walk:
  context_provided: "Semantically retrieved context"
  expected_improvement: "25-35% accuracy increase vs baseline"
  measure_against: "baseline-v1, experiment_crawl"
```

---

### Phase 3: RUN - AI Integration

**Duration**: Weeks 7-9

**Goal**: MCP server, Claude Code integration, validated quality.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RUN PHASE DELIVERABLES                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AI INTEGRATION                                                              â”‚
â”‚  â”œâ”€â”€ MCP Server exposing tools                                              â”‚
â”‚  â”‚   â”œâ”€â”€ search_code(query) â†’ relevant symbols                             â”‚
â”‚  â”‚   â”œâ”€â”€ trace_workflow(entry_point) â†’ call graph                          â”‚
â”‚  â”‚   â”œâ”€â”€ get_doctype(name) â†’ schema + relationships                        â”‚
â”‚  â”‚   â””â”€â”€ explain_domain(module) â†’ bounded context summary                  â”‚
â”‚  â”‚                                                                          â”‚
â”‚  â”œâ”€â”€ Claude Code configuration                                              â”‚
â”‚  â””â”€â”€ Cursor integration (if time permits)                                   â”‚
â”‚                                                                              â”‚
â”‚  QUALITY VALIDATION                                                          â”‚
â”‚  â”œâ”€â”€ A/B experiments (with context vs without)                              â”‚
â”‚  â”œâ”€â”€ Statistical significance testing                                       â”‚
â”‚  â”œâ”€â”€ Regression suite (catch quality drops)                                 â”‚
â”‚  â””â”€â”€ User satisfaction survey (internal)                                    â”‚
â”‚                                                                              â”‚
â”‚  DOCUMENTATION                                                               â”‚
â”‚  â”œâ”€â”€ API reference                                                          â”‚
â”‚  â”œâ”€â”€ Integration guide                                                      â”‚
â”‚  â””â”€â”€ Evaluation report                                                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Success Criteria**:

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Accuracy delta vs baseline | +30%+ | `(enhanced - baseline) / baseline` |
| Completeness delta | +25%+ | Same calculation |
| File accuracy | 75%+ | Correct files referenced |
| Domain concept recall | 70%+ | Correct concepts mentioned |
| Questions improved | 80%+ | % where enhanced > baseline |
| Questions degraded | < 5% | % where enhanced < baseline |

---

## Measurement Framework

### KPIs by Phase

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KPI EVOLUTION                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  PHASE      â”‚ PRIMARY KPI              â”‚ SECONDARY KPIs                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Baseline   â”‚ Avg accuracy score       â”‚ Completeness, file accuracy        â”‚
â”‚  Crawl      â”‚ Symbol coverage          â”‚ Parse success, index time          â”‚
â”‚  Walk       â”‚ Retrieval precision      â”‚ Recall, latency                    â”‚
â”‚  Run        â”‚ Accuracy delta           â”‚ User satisfaction, regression rate â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Version Tracking Schema

```typescript
interface ExperimentVersion {
  id: string;                    // "v0.3.2"
  date: string;                  // "2026-01-14"
  phase: "crawl" | "walk" | "run";

  // What changed
  changes: string[];             // ["Added bge-large embeddings", "Increased chunk size"]

  // Configuration
  config: {
    embedding_model: string;
    chunk_size: number;
    retrieval_k: number;
    reranker: string | null;
  };

  // Results on standard test set
  results: {
    accuracy: number;            // Average 1-5
    completeness: number;
    precision: number;           // RAGAs
    recall: number;
    latency_p95_ms: number;
  };

  // Comparison
  vs_baseline: {
    accuracy_delta: number;      // +0.31 (31% improvement)
    completeness_delta: number;
    precision_delta: number;
  };

  vs_previous: {
    version: string;             // "v0.3.1"
    accuracy_delta: number;
  };
}
```

### Dashboard View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODE INTELLIGENCE PLATFORM â€” PROGRESS DASHBOARD                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  CURRENT: v0.5.0 (Walk Phase)          TARGET: +30% accuracy vs baseline    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   ACCURACY      â”‚  â”‚  COMPLETENESS   â”‚  â”‚   PRECISION     â”‚             â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚             â”‚
â”‚  â”‚    3.8 / 5      â”‚  â”‚    3.5 / 5      â”‚  â”‚    0.78         â”‚             â”‚
â”‚  â”‚    â–² +65%       â”‚  â”‚    â–² +67%       â”‚  â”‚    (target: 75%)â”‚             â”‚
â”‚  â”‚   vs baseline   â”‚  â”‚   vs baseline   â”‚  â”‚                 â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  VERSION HISTORY (Accuracy)                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  5.0 â”‚                                          TARGET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚      â”‚                                                                      â”‚
â”‚  4.0 â”‚                                    â•­â”€â”€â”€â”€â”€â— v0.5.0 (current)         â”‚
â”‚      â”‚                              â•­â”€â”€â”€â”€â”€â•¯                                 â”‚
â”‚  3.0 â”‚                        â•­â”€â”€â”€â”€â”€â•¯  â— v0.4.0                            â”‚
â”‚      â”‚                  â•­â”€â”€â”€â”€â”€â•¯                                             â”‚
â”‚  2.5 â”‚            â•­â”€â”€â”€â”€â”€â•¯  â— v0.3.0                                        â”‚
â”‚      â”‚      â•­â”€â”€â”€â”€â”€â•¯                                                         â”‚
â”‚  2.0 â”‚â”€â”€â”€â”€â”€â”€â— baseline                                                      â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚        Week 1    Week 3    Week 5    Week 7    Week 9    Week 11           â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  RECENT EXPERIMENTS                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â”‚ Version â”‚ Change              â”‚ Accuracy â”‚ Delta    â”‚ Status          â”‚ â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ v0.5.0  â”‚ Added reranker      â”‚ 3.8      â”‚ +0.3     â”‚ âœ… Deployed     â”‚ â”‚
â”‚  â”‚ v0.4.1  â”‚ Larger chunks (2K)  â”‚ 3.5      â”‚ +0.2     â”‚ âœ… Deployed     â”‚ â”‚
â”‚  â”‚ v0.4.0  â”‚ bge-large embedding â”‚ 3.3      â”‚ +0.4     â”‚ âœ… Deployed     â”‚ â”‚
â”‚  â”‚ v0.3.0  â”‚ Semantic search     â”‚ 2.9      â”‚ +0.6     â”‚ âœ… Deployed     â”‚ â”‚
â”‚  â”‚ baselineâ”‚ No context          â”‚ 2.3      â”‚ -        â”‚ ğŸ“Š Reference    â”‚ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Weekly Checkpoint Template

```yaml
# weekly-checkpoint-week-04.yaml
week: 4
phase: "Walk"
date: "2026-02-10"

# What was built
deliverables:
  - "Implemented embedding generation with bge-large"
  - "Set up LanceDB vector index"
  - "Basic semantic search working"

# Current metrics
metrics:
  symbol_coverage: 0.94
  retrieval_precision: 0.68
  retrieval_recall: 0.72
  latency_p95_ms: 380

# vs targets
target_comparison:
  precision: { current: 0.68, target: 0.70, status: "on_track" }
  recall: { current: 0.72, target: 0.75, status: "on_track" }

# vs baseline
baseline_comparison:
  accuracy_delta: "+28%"
  completeness_delta: "+32%"

# Blockers
blockers:
  - "ERPNext hook extraction incomplete"

# Next week focus
next_week:
  - "Complete hook extraction"
  - "Add hybrid retrieval (keyword + semantic)"
  - "Run full experiment on test set"
```

---

## Crawl-Walk-Run Summary

| Phase | Focus | Human Role | AI Role | Proof |
|-------|-------|------------|---------|-------|
| **Crawl** | Extraction | Reviews all output | Generates suggestions | Coverage metrics |
| **Walk** | Retrieval | Validates relevance | Retrieves context | Precision/recall |
| **Run** | Integration | Uses tool normally | Provides context autonomously | Accuracy delta |

---

## Related

- [Platform Capabilities](./02-Capabilities.md)
- [Enterprise Tooling](../03-AI-Platform/05-Enterprise-Tooling.md)
- [Quality Metrics](../03-AI-Platform/04-Quality-Metrics.md)
- [Technology Stack](../02-Engineering/03-Technology-Stack.md)

---

*Last Updated: 2026-01-14*
